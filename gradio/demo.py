from io import StringIO

import gradio as gr
import time

import gradio.utils
from pdfminer.high_level import extract_text_to_fp
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
import chromadb
from zhipuai import ZhipuAI
from dotenv import load_dotenv
from utils.logger import setup_logger

load_dotenv()
logger = setup_logger()

EMBED_MODEL = SentenceTransformer('all-MiniLM-L6-v2')
CHROMA_CLIENT = chromadb.PersistentClient(
    path="./db/chroma_db",
    settings=chromadb.Settings(anonymized_telemetry=False)
)
COLLECTION = CHROMA_CLIENT.get_or_create_collection("rag_docs")
CHAT_MODEL = ZhipuAI()

def extract_pdf_text(filepath: str):
    """ä»pdfä¸­æå–æ–‡å­—"""
    output = StringIO()
    with open(filepath, 'rb') as file:
        extract_text_to_fp(file, output)
    return output.getvalue()


def process_pdf(file: gradio.utils.NamedString, progress=gr.Progress()):
    """å¤„ç†ä¸Šä¼ çš„pdfæ–‡ä»¶"""
    try:
        progress(0.2, desc="è§£æPDF...")
        print(f"===> {file.name}")
        text = extract_pdf_text(file.name)

        progress(0.4, desc="åˆ†éš”æ–‡æœ¬...")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)
        chunks = text_splitter.split_text(text)

        progress(0.6, desc="ç”ŸæˆåµŒå…¥...")
        embeddings = EMBED_MODEL.encode(chunks)

        progress(0.8, desc="å­˜å‚¨å‘é‡...")
        existed_ids = COLLECTION.get()['ids']
        if existed_ids:
            COLLECTION.delete(ids=existed_ids)
        ids = [str(i) for i in range(len(chunks))]
        COLLECTION.add(
            ids=ids,
            embeddings=embeddings,
            documents=chunks
        )

        progress(1.0, desc="å®Œæˆ")
        return f"PDFå¤„ç†å®Œæˆï¼Œå·²å­˜å‚¨{len(chunks)}ä¸ªæ–‡æœ¬å—"
    except Exception as e:
        return f"å¤„ç†å¤±è´¥ï¼š {str(e)}"


def stream_answer(question: str, progress=gr.Progress()):
    """å›ç­”é—®é¢˜"""
    try:
        progress(0.2, desc="ç”Ÿæˆé—®é¢˜åµŒå…¥...")
        question_embedding = EMBED_MODEL.encode(question)

        progress(0.4, desc="æ£€ç´¢ç›¸å…³å†…å®¹...")
        relavant_docs = COLLECTION.query(
            query_embeddings=question_embedding,
            n_results=3
        )
        print(relavant_docs)

        context = "\n".join(relavant_docs["documents"][0])
        prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡
        {context}

        é—®é¢˜ï¼š {question}
        è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ç­”æ¡ˆï¼Œè¯·å›ç­”â€œæˆ‘ä¸ç¡®å®šâ€
        """
        response = CHAT_MODEL.chat.completions.create(
            model="glm-4",
            messages=[
                {"role": "user", "content": prompt}
            ],
            stream=True
        )
        full_answer = ""
        for chunk in response:
            full_answer += chunk.choices[0].delta.content
            yield full_answer, "ç”Ÿæˆä¸­..."
        yield full_answer, "å®Œæˆ"
    
    except Exception as e:
        logger.exception(e)
        yield f"é‡åˆ°é”™è¯¯ï¼š {str(e)}"


with gr.Blocks(
    title="æœ¬åœ°é—®ç­”ç³»ç»Ÿ"
) as demo:
    gr.Markdown("# ğŸ§  æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("## ğŸ“ƒæ–‡æ¡£å¤„ç†åŒº")
            with gr.Group():
                file_input = gr.File(label="ä¸Šä¼ PDFæ–‡æ¡£", file_types=[".pdf"])
                upload_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                upload_status = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False)
            gr.Markdown("## â“æé—®åŒº")
            with gr.Group():
                question_input = gr.Textbox(label="è¾“å…¥é—®é¢˜", lines=4, placeholder="ä¾‹å¦‚ï¼šæœ¬æ–‡æ¡£çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")
                ask_btn = gr.Button("ğŸ” å¼€å§‹æé—®", variant="primary")
                status_display = gr.HTML("")
        with gr.Column(scale=3):
            gr.Markdown("## ğŸ“ ç­”æ¡ˆå±•ç¤º")
            answer_output = gr.Textbox(label="æ™ºèƒ½å›ç­”", interactive=False, lines=25, autoscroll=True)
            gr.Markdown("å›ç­”ç”Ÿæˆå¯èƒ½éœ€è¦1~2åˆ†é’Ÿ")

    # ä¸Šä¼ æ–‡ä»¶
    upload_btn.click(
        fn=process_pdf,
        inputs=file_input,
        outputs=upload_status
    )

    # æé—®æŒ‰é’®
    ask_btn.click(
        fn=stream_answer,
        inputs=question_input,
        outputs=[answer_output, status_display]
    )

demo.launch(
    show_error=True,
    ssl_verify=False
)

